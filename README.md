# Explainable Multi-Agent Generative Recommendation System for Personalized Learning

---

## ğŸ“Œ Project Overview

This project proposes an **Explainable Multi-Agent Generative Recommendation System**
for **personalized e-learning**.  
It combines **Agentic AI, Generative AI (LLMs), and Explainable AI (XAI)** to recommend
*and generate* adaptive learning paths while providing **transparent and trustworthy explanations**.

---

## ğŸ¯ Motivation & Context

Current e-learning recommendation systems (collaborative filtering, deep learning)
suffer from major limitations:

- âŒ **Lack of adaptability**: no dynamic reasoning or planning
- âŒ **No content generation**: they recommend but do not create learning material
- âŒ **Black-box models**: lack of explainability â†’ low user trust

This project addresses these issues through a **collaborative multi-agent architecture**
capable of reasoning, generating, and explaining personalized learning pathways.

---

## ğŸ§ª Scientific Objectives

- Design a **collaborative multi-agent architecture** (memory, planning, communication)
- Integrate **LLMs + RAG** for personalized content generation
- Provide **hybrid explanations** (post-hoc XAI + agentic reasoning)
- Evaluate **recommendation quality** and **user trust**

---

## ğŸ§  Multi-Agent Architecture

| Agent | Role | Technologies |
|------|-----|-------------|
| **Profiling Agent** | Learner profile & learning style analysis | Embeddings, clustering, LLM |
| **Path Planning Agent** | Pedagogical path planning | Graph search, RL, heuristics |
| **Content Generator Agent** | Generates lessons & quizzes | LLM, RAG |
| **Recommendation Agent** | Ranks and recommends resources | Hybrid filtering, LLM |
| **XAI Agent** | Explains decisions | SHAP, LIME, counterfactuals |
| **Orchestrator** | Coordinates agents | LangGraph, AutoGen |

---

## ğŸ”„ Technical Pipeline

1. Learner interaction collection  
2. Embedding encoding  
3. Agentic planning  
4. Content generation via **LLM + RAG**  
5. Recommendation & ranking  
6. Explainability (XAI)  
7. Evaluation  

---

## ğŸ” Explainable AI Methods

| Method | Example |
|------|--------|
| **SHAP / LIME** | Feature importance from learner profile |
| **Counterfactuals** | â€œIf your score increased by +10%, resource X would be recommendedâ€ |
| **Chain-of-Thought** | Structured agent reasoning explanations |

---

## ğŸ“Š Datasets

- **OULAD**
- **EdNet**
- **Moodle interaction logs**

---

## ğŸ“ˆ Evaluation Metrics

### Recommendation
- NDCG
- MRR
- Recall@K

### Generation
- ROUGE
- BERTScore
- Human evaluation

### Explainability
- Faithfulness
- Plausibility
- User trust score

---

## ğŸ† Expected Contributions

- âœ… A unified **Agentic AI + GenAI + XAI framework** for e-learning
- âœ… Cognitive explanation methods based on **multi-agent reasoning**
- âœ… Empirical evaluation of **user trust and transparency**

---

## ğŸ§© Project Structure

```text
genai_recommender/
â”œâ”€â”€ agents/            # Individual agent implementations
â”œâ”€â”€ orchestrator/      # Agent coordination logic
â”œâ”€â”€ utils/             # Shared utilities
â”œâ”€â”€ config/            # Configuration files
â”œâ”€â”€ main.py            # Main pipeline
â”œâ”€â”€ demo.py            # Demo / experiments
â””â”€â”€ README.md
